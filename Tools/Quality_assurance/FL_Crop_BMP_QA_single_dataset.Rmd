---
date: "`r Sys.Date()`"
author: "Jeff White, Univ. Florida"
output: 
  pdf_document:
    latex_engine: pdflatex
    keep_tex: yes
---

```{r setup, echo=FALSE, comment=NA}
knitr::opts_chunk$set(echo = TRUE)
# Specify the name of the dataset here as data_set_name.
data_set_name <- "FDACS_UFGA8201_peanut.94.xlsx"
file_path <- file.path("Test_data", data_set_name)

```

---
title: "`r paste0('**Quality Assurance Testing for the Crop BMP Dataset: \n', data_set_name, "**")`"
---

# 1. Introduction

In preparing datasets based on the BMP data template, researchers need to check that their data are entered correctly, that the dataset is formatted as intended, and that variables are correctly defined. The goal of this report is to allow users to conduct a series of quality assurance (QA) tests on a dataset prior to submitting the data to a repository or funding agency. The underlying R script reviews crop BMP datasets according to the "four C's", whereby a dataset is:

1.  _Correct_: The values are accurate within the expected range of measurement error. We emphasize that the main error-checking should be done as a part of the normal data management pipeline prior to loading into the BMP template.
2.  _Complete_: The dataset is complete enough to enable further analysis without researchers having to seek guidance on how the crop was grown, weather conditions, etc.
3.  _Coherent_: Identifiers (keys) used to link data across sheets are used consistently.
4.  _Compatible_: By linking the BMP terminology to the ICASA standards, we expect that datasets can be used with a wide range of tools including artificial intelligence, machine learning and either simulation or statistical models.

This document (the exported PDF) is produced by running the knit command within RStudio. It alternates between text (such as this section), blocks of the R script, and blocks of output from R. Users who are familiar with R and R Markdown should feel free to modify the markdown file as needed.

```{r load-libraries-set-wd, echo = FALSE, comment=NA}
library(knitr)
library(ggplot2)
library(maps)
library(mapdata)
library(ggrepel)
library(openxlsx2)  #Required for manipulating rows and columns of Excel
library(reshape2)

#' Sets the working directory to the folder where the script, the template  
#' and the variable list reside. The new file will also be created here.
# setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

## 1.1. Checking that the file is read as expected

We first list all sheets in the file `r data_set_name`. The list includes sheets
that are defined but have no data. 

```{r list-sheets, echo=FALSE, comment=""}
#' Load workbook
wb <- wb_load(file_path)


#' Retrieve a list of the names of all sheets in the dataset.
ls_sheets <- wb_get_sheet_names(wb) # Copies sheet names into a list
options(width = 84)
print(unname(ls_sheets))
```

\newpage

```{r , include=FALSE}
#' This loop should create approximately 30 sheets.
for (i in 1:length(ls_sheets)) {
  sheet_name <- ls_sheets[[i]]
  cat(sheet_name)
  df_name <- make.names(sheet_name)
  df_temp <- wb_to_df(wb, sheet = sheet_name, colNames = TRUE,
                       start_row=4, na.strings = "",
                     skip_empty_rows = TRUE,
                     skip_empty_cols = TRUE)
  assign(df_name, df_temp)
}
```

# 2.0. Correct and Complete?: Summarizing the Content of Individual Sheets

Summaries are generated for the contents of each sheet except for the first three sheets, which contain instructions, and the last three, which are the dictionaries. If sufficient numeric data are present, boxplots are created for any numeric variables, including management levels. 

Results for each sheet should be checked to make sure they match expectations for all variables. The QA tool is *not* meant as the primary means of detecting incorrect values. We assume the researchers have already conducted extensive quality control.

## 2.1. Summaries for each sheet (Tabular summaries first, then box plots of numeric variables).

If numeric data appear in tables of frequencies, this means the data for the variable has been interpreted as text (character sting). This can arise if there are any non-numeric values such as "." in the original data. Be sure to check rows below the actual data in case a character has inadvertently been entered below the main data.

Depending on the amount of data in the sheets, the corresponding group of box plots may appear after the summary of the next sheet (i.e., the box plots will be slightly out of order). 

```{r check-content-of-sheets, echo=FALSE, comment=NA, warning=FALSE, fig.height=1.2, fig.width=3.2}
#```{r check-content-of-sheets, echo=FALSE, comment=NA, warning=FALSE,  results='hold' , fig.height = 4.4}
options(width = 92) # Allows longer lines to display without wrapping

# Prior to processing dataframes, we create functions to test for sufficient
# numeric data.
has_5_numeric_values <- function(column) {
  sum(!is.na(column) & is.numeric(column)) >= 5
}

#' Prior to beginning processing, we need to limit  E3..Plots to six variables
#' because users have the option of providing plot maps that may cause additional
#' variables to be created
E3..Plots <- E3..Plots[ , c(1:6)]

#' Create function for summarizing non-numeric data
# Function to create a combined frequency table for all non-numeric variables in a data frame
create_combined_frequency_table <- function(df) {
  # Check if the data frame is empty
  if (nrow(df) == 0 || ncol(df) == 0) {
    return(data.frame(Variable = character(0), Value = character(0), Frequency = integer(0)))
  }
  
  # Identify non-numeric columns
  non_numeric_vars <- sapply(df, is.factor) | sapply(df, is.character)
  
  # If no non-numeric columns, return an empty data frame
  if (!any(non_numeric_vars)) {
    return(data.frame(Variable = character(0), Value = character(0), Frequency = integer(0)))
  }
  
  # List to store frequency tables
  freq_tables <- list()
  
  # Loop through non-numeric variables
  for (var in names(df)[non_numeric_vars]) {
    # Create frequency table
    freq_table <- as.data.frame(table(df[[var]]))
    colnames(freq_table) <- c("Value", "Frequency")
    
    # Add variable name as the first column
    freq_table <- cbind(Variable = var, freq_table)
    
    # Append to the list
    freq_tables[[var]] <- freq_table
  }
  
  # Combine all frequency tables into a single data frame
  combined_freq_table <- do.call(rbind, freq_tables)
  # Truncate Variable and Value to avoid printing issues
  combined_freq_table$Variable <- substr(combined_freq_table$Variable, 1, 27)
  combined_freq_table$Value    <- substr(combined_freq_table$Value   , 1, 45)

  return(combined_freq_table)
}

# Create function to replace -99 with NA in numeric columns
replace_neg99_with_na <- function(df) {
  # Apply the replacement only to numeric columns
  df[] <- lapply(df, function(col) {
    if (is.numeric(col)) {
      is.na(col) <- col == -99
    }
    return(col)
  })
  return(df)
}

# Create function to left-align column names based on maximum value length.
left_align_column_names <- function(df) {
  # Find the maximum length of values in each column and the column name length
  max_lens <- sapply(seq_along(df), function(i) {
    col <- df[[i]]
    if (is.character(col)) {
      max_value_length <- max(nchar(col), na.rm = TRUE)
    } else {
      max_value_length <- max(nchar(as.character(col)), na.rm = TRUE)
    }
    max(nchar(names(df)[i]), max_value_length)
  })
  
  # Add spaces to the right of each column name to make them the same length as the longest value in the column or the column name itself
  new_colnames <- sapply(seq_along(names(df)), function(i) {
    name <- names(df)[i]
    max_len <- max_lens[i]
    paste0(name, strrep(" ", max_len - nchar(name)))
  })
  
  # Assign the new column names to the data frame
  names(df) <- new_colnames
  
  return(df)
}

# Find position of 'M1..Experiments' in ls_sheets
data_start_position <- which(ls_sheets == "M1. Experiments") # Get start of actual data
dictionary_length <- 3 #Number of dictionary sheets

# ls_sheets is the list of dataframe names
for (i in data_start_position:(length(ls_sheets) - dictionary_length)) {
  sheet_name <- ls_sheets[[i]]
  name_of_df <- make.names(sheet_name)
  cat(paste0("START processing ", name_of_df, "\n\n"))
  df_being_checked <- get(name_of_df)  # Convert temporary name as string to valid df name.

  # Apply function to summarize non-numeric data
  df_frequencies <- create_combined_frequency_table(df_being_checked)
  df_frequencies$Variable <- format(df_frequencies$Variable, justify = "left")
  df_frequencies$Value <- format(df_frequencies$Value, justify = "left")

  # Set a higher value for max.print
  options(max.print = 200)  # Adjust the value as needed
  df_frequencies <- left_align_column_names(df_frequencies)
  print(df_frequencies, row.names = FALSE)
  cat("\n")
 
  # Start of processing for numeric data
  # set working df to empty
  melted_data <- data.frame()
  selected_columns <- list()
  # Loop through columns of df
  for (j in 1:ncol(df_being_checked)) {
    # Check condition for selecting the column
    # The first test requires a variance > 0 which indicate all values in the column differ.
    # The second test checks that the variance is not NA, which would mean all values are NA.
    if (var(df_being_checked[, j], na.rm = TRUE) > 0 
        && !is.na(var(df_being_checked[, j], na.rm = TRUE))) {
      # Store the selected column along with its name
      selected_columns[[colnames(df_being_checked)[j]]] <- df_being_checked[, j]
    }
  }
  # Convert the list to a dataframe
  numeric_columns <- as.data.frame(selected_columns)
  
  # Convert values of -99 to NA
  numeric_columns <- replace_neg99_with_na(numeric_columns)
  
  # Create boxplot for all sheets that have sufficient numeric data (nrow > 5).
  # Test for no numeric data and skip boxplot
  if (
         (length(names(numeric_columns))) > 0 
      && (nrow(numeric_columns) > 5)
  ) {
    
    # Print summary of numeric data
    print(summary(numeric_columns))
    
    # Create a horizontal box plot with individual numerical axes
    # Melt the dataframe to long format using reshape2 package
    melted_data <- reshape2::melt(numeric_columns)
    
# Loop through unique variables and create boxplots
for(m in unique(melted_data$variable)){
  # Subset data for the current variable
  subset_data <- melted_data[melted_data$variable == m, ]
  
  # Create boxplot for the subsetted data
        boxplot <- ggplot(subset_data, aes(x = variable, y = value)) +
        ggplot2::geom_boxplot() +
        stat_summary(fun.y=mean, geom="point", shape=20, size=6, color="red", fill="red") +
        ggplot2::ggtitle(paste0("Boxplot for ", name_of_df)) +
        xlab(m)+
        ggplot2::coord_flip() +
        theme(plot.title = element_text(size = 9), axis.title.y = element_text(size = 7)) + # Adjust the size as needed
        ggplot2::theme(axis.title.x = ggplot2::element_blank()) + # Suppress x-axis text
        ggplot2::theme(axis.text.y = ggplot2::element_blank())  # Suppress y-axis text
      print(boxplot)
      
      cat("\n")
    }

    
        cat("\n")
  } 
  
  cat(paste0("End of processing for ", name_of_df, "\n"))
  cat("*            ===================================================            *\n")
  cat("\n")
  
}
```

---

## 2.2. Correct Dates? Are events sequenced as expected?

Dates of key management events such as plantings, irrigations and harvests are sometimes
entered incorrectly. A common problem is inversion of days and months (is '3/5' "March 5" or "3 April"?). To check dates, we plot management events for each combination of Experiment, Site and Year along a timeline. 
To reduce the potential number of plots, data from different treatments and replicates are pooled together. This means some timelines may include multiple instances of plantings, fertilizer applications, harvests or other events.
We currently do not consider crop phenology such as flowering or maturity dates.

```{r check-dates, echo = FALSE, comment="", fig.height = 8}

#' Create cropping calendar for the dataset.
#' Assemble dates in different dataframes
#' E5. Planting
#' E6. Irrigation
#' E7. Fertilizer
#' E8. Organic Amendments
#' E9. Tillage
#' E11. Harvest
#' To facilitate processing, we extract the date and assign an event code. 
#' Because some sheets have no data (nrows = 0), we have to consider two cases.
E5Planting <- E5..Planting[,c(1:3,5)]
E5Planting$Event <- "P"   # Coded for planting
colnames(E5Planting) <- c("Experiment ID", "Site", "Year", "Date", "Event")

E6Irrigation <- E6..Irrigation[,c(1:3,5)]
if(nrow(E6Irrigation) > 0){E6Irrigation$Event <- "I"   # Coded for irrigation
} else {E6Irrigation$Event <- character(0)}
  colnames(E6Irrigation) <- c("Experiment ID", "Site", "Year", "Date", "Event")

E7Fertilizer <- E7..Fertilizer[,c(1:3,5)]
if(nrow(E7Fertilizer) > 0){E7Fertilizer$Event <- "F"   # Coded for fertilizer
} else {E7Fertilizer$Event <- character(0)}
colnames(E7Fertilizer) <- c("Experiment ID", "Site", "Year", "Date", "Event")

E8OrganicAmend <- E8..Organic.Amendments[,c(1:3,5)]
if(nrow(E8OrganicAmend) > 0){E8OrganicAmend$Event <- "O"   # Coded for Organic amendments
} else {E8OrganicAmend$Event <- character(0)}
colnames(E8OrganicAmend) <- c("Experiment ID", "Site", "Year", "Date", "Event")

E9Tillage <- E9..Tillage[,c(1:3,5)]
if(nrow(E9Tillage) > 0){E9Tillage$Event <- "T"   # Coded for Tillage
} else {E9Tillage$Event <- character(0)}
colnames(E9Tillage) <- c("Experiment ID", "Site", "Year", "Date", "Event")

E11Harvest <- E11..Harvest[,c(1:3,5)]
if(nrow(E11Harvest) > 0){E11Harvest$Event <- "H"   # Coded for Harvest
  } else {E11Harvest$Event <- character(0)}
colnames(E11Harvest) <- c("Experiment ID", "Site", "Year", "Date", "Event")

#' With the six temporary dataframes in hand, we merge them to create the 
#' dataframe df_dates, removing any dataframe that lacks date information.

#'  List of data frames
df_list <- list(E5Planting, E6Irrigation, E7Fertilizer, E8OrganicAmend, 
                E9Tillage, E11Harvest)

# Remove empty data frames from the list
df_list <- df_list[sapply(df_list, function(x) nrow(x) > 0)]

# Concatenate data frames
if (length(df_list) > 0) {
  df_dates <- do.call(rbind, df_list)
} else {
  df_dates <- data.frame()  # Return an empty data frame if all are empty
}

#' The list of merged dates can be displayed.
df_dates <- unique(df_dates) 
#' Often data from replicates or treatments will identical values, so we use unique() 
#' to simplify the dataset.
#print(df_dates) # To check outputs

planting_dates <- aggregate(Date ~ `Experiment ID` + Site + Year, data = subset(df_dates, Event == "P"), FUN = min)

# Calculate DAP relative to Planting event
# Merge planting_dates with df_dates
df_dates <- merge(df_dates, planting_dates, 
                     by = c("Experiment ID", "Site", "Year"), suffixes = c("", ".Planting"))

# Calculate DAP relative to Planting event
df_dates$DAP <- with(df_dates, Date - Date.Planting)
#print(df_dates) # To check outputs

# Create a separate data frame for geom_text
df_dates$DAP <- as.numeric(df_dates$DAP)

# Define custom point shapes and colors
point_shapes <- c(T = 16, P = 19, F = 17, I = 1, C = 12, H = 15, O = 13)
point_names <- c(T = "Tillage", P = "Planting", F = "Fertilizer", I = "Irrigation", H = "Harvest", C= "Agrochemicals", O= "Manure")
point_colors <- c(T = "brown", P = "dark green", F = "dark gray", I = "blue", H = "#CC9933", C= "red", O= "dark orange")
label_y_position <- c(T = -.5, P = -1.0, F = 1.5, I = 2.0, C = 1.0, H = 1.5, O = 1.3)

# Reorder the levels of the y-axis factor in reverse order
df_dates$"Experiment ID" <- factor(df_dates$"Experiment ID", levels = rev(levels(as.factor(df_dates$"Experiment ID")))) 

# Plot parallel timelines with labels above or below events and without legend
ggplot(df_dates, aes(x = DAP, y = paste(`Experiment ID`, Site, Year), 
                        shape = Event, color = Event, label = Event)) +
  geom_point(size = 2) +
  geom_text(aes(y = ifelse(Event %in% c("P", "F", "I", "C", "T", "H", "O"), paste(`Experiment ID`, Site, Year), NA)), 
            position = position_dodge(width = 0.2), size = 3, 
            vjust = label_y_position[subset(df_dates, Event %in% c("P", "F", "I", "C", "T", "H", "O"))$Event], 
            show.legend = FALSE) +
  scale_x_continuous(expand = c(.2, 0), name = "Days after planting") +
  theme_linedraw() +
  theme(legend.position = "plot") +
  scale_shape_manual(values = point_shapes) +
  scale_color_manual(values = point_colors, labels = point_names) +
  theme(panel.grid.major.y = element_line(color = "brown", linewidth = 0.3),  # Change color and width of horizontal grid lines
        panel.grid.major.x = element_blank(),  # Suppress vertical grid lines
        panel.grid.minor.x = element_blank(),  # Suppress vertical grid lines
        panel.grid.minor.y = element_blank(),
        plot.caption = element_text(hjust = 0)) + # Left-align the caption
  labs(title = "Timelines for Experiments, Sites and Years", y = NULL, 
     caption = "Replicates or treatments having identical event dates are shown as a single line.")
```

\newpage

## 2.3. Correct geocoordinates? Are locations mapped as expected?

Experience shows that datasets often have errors in location data. This section checks that any reported geocoordinates are roughly correct by mapping. Geocoordinates may appear in four sheets:

-   M2. Sites
-   E2. Fields
-   S1. Soil Metadata
-   W1. Weather Station Metadata

To facilitate processing, we extract the geocoordinates and the location name, and add as 'Source' the name of the individual sheet containing the data.

```{r get-geocoords, echo = FALSE, comment=""}
# Get the map data for Florida
florida_map <- map_data("state", region = "florida")

M2Sites <- M2..Sites
M2Sites$Source <- "M2. Sites"
M2Sites <- M2Sites[, c(8, 1, 6, 7)]
colnames(M2Sites) <- c("Source", "Location", "Lat", "Long")

E2Fields <- E2..Fields
E2Fields$Source <- "E2. Fields"
E2Fields <- E2Fields[, c(20, 3:5)]
colnames(E2Fields) <- c("Source", "Location", "Lat", "Long")

S1Soils <- S1..Soil.Metadata
S1Soils$Source <- "S1. Soil Meta"
S1Soils <- S1Soils[, c(12, 1, 6, 7)]
colnames(S1Soils) <- c("Source", "Location", "Lat", "Long")

W1Weather <- W1..Weather.Station.Metadata
W1Weather$Source <- "W1. Weather"
W1Weather <- W1Weather[, c(9, 1, 3, 4)]
colnames(W1Weather) <- c("Source", "Location", "Lat", "Long")

#' With the four temporary data frames in hand, we merge them to create the 
#' data frame df_geo_data, removing any data frame that lacks geocoordinates.

#' List of data frames
df_list <- list(M2Sites, E2Fields, S1Soils, W1Weather)

# Remove empty data frames from the list
df_list <- df_list[sapply(df_list, function(x) nrow(x) > 0)]

# Concatenate data frames
if (length(df_list) > 0) {
  df_geo_data <- do.call(rbind, df_list)
} else {
  df_geo_data <- data.frame()  # Return an empty data frame if all are empty
}
```

---

### 2.3.1. List of all expected geocoordinates

```{r list-geocoords, echo = FALSE, comment=""}
#' The list of merged geocoordinates is displayed.
df_geo_data_map <- df_geo_data
df_geo_data$Source <- format(df_geo_data$Source, justify = "left")
df_geo_data$Location <- format(df_geo_data$Location, justify = "left")

df_geo_data2 <- left_align_column_names(df_geo_data)

print(df_geo_data2, row.names = FALSE)
```

---

### 2.3.2. Displaying the reference map of Florida with any reported locations

Here we use a map of Florida as the base. If latitude or longitude values are very far off (e.g., if the values are reversed or longitude is assigned a positive value for anywhere in the Americas), the map will display, but it may be distorted and not look like the expected base map of Florida.

```{r, map-geocoords, echo = FALSE, comment=""}

#' Using ggplot(), a base map of Florida is created, then overlain with the 
#' locations as points using different colors depending on the variable Source.
ggplot() +
  geom_polygon(data = florida_map, aes(x = long, y = lat, group = group), 
               fill = "lightblue", color = "black") +
  
  # Add the geocoordinates as points
  geom_point(data = df_geo_data_map, aes(x = Long, y = Lat, color = Source), 
             size = 2, position = position_jitter(width = 0.05, height = 0.05)) +
  scale_color_manual(values = 
                       c("M2. Sites" = "red", "E2. Fields" = "green", 
                         "S1. Soil Meta" = "brown", "W1. Weather" = "blue")) +
  # Customize the plot appearance
  labs(title = "Geocoordinates of Reported Sites for Research, Soils or Weather", x = "Longitude", y = "Latitude") +
  theme_bw()
```

The option position = position_jitter is used so that if there are a large number of points with nearly identical locations, these are spread out slightly.

\newpage

## 2.4. Completeness of sheets: Checking whether sheets present in the template are missing from the dataset

Users may add sheets as needed but are discouraged from deleting sheets.

```{r, sheets-present, echo = FALSE, comment=""}

template_sheets <- c("START HERE", "Terminology", "List of sheets and keys", "M1. Experiments", "M2. Sites", "M3. Experimental Design", "E1. Treatments", "E2. Fields", "E3. Plots", "E4. Crop Information", "E5. Planting", "E6. Irrigation", "E7. Fertilizer", "E8. Organic Amendments", "E9. Tillage", "E10. Chemical Applications", "E11. Harvest", "E12. Preplant Soil", "O1. Analysis Methods", "O2. Yield Summary", "O3. Crop Growth",  "O4. Crop Health",  "O5. Soil Surface Properties", "O6. Soil Layer Properties", "O7. Water", "S1. Soil Metadata",   "S2. Soil Layer Properties", "W1. Weather Station Metadata", "W2. Daily Weather Data", 
 "Z1. Dictionary Metadata", "Z2. Dictionary Observations", "Z3. Dictionary Soils Weather" )

compare_sheet_names <- function(ls_sheets, template_sheets) {
  # Convert both lists to character vectors
  all_sheets <- unlist(ls_sheets)
  template_sheets <- unlist(template_sheets)
  
  # Find mismatches
  missing_in_dataset <- setdiff(template_sheets, all_sheets)
  missing_in_template <- setdiff(all_sheets, template_sheets)
  
  if (length(missing_in_dataset) == 0 & length(missing_in_template) == 0) {
    cat("The sheet names match.\n")
  } else {
    if (length(missing_in_dataset) > 0) {
      cat("The following sheets are in the template workbook but not in the dataset:\n")
      print(missing_in_dataset)
    }
    if (length(missing_in_template) > 0) {
      cat("The following sheets are in the dataset but not in the template workbook:\n")
      print(missing_in_template)
    }
  }
}

# Compare the sheets that contain data

compare_sheet_names(ls_sheets, template_sheets)

```

## 2.5. Completeness of data in individual sheets

To assess completeness, we need to know whether most of the variables actually have data values (e.g., are not empty cells). Below is a count of total values for variables used in each sheet. To avoid the output being split into two sections, variable names that are longer than 30 characters are truncated.

```{r complete-sheets, echo = FALSE, comment=""}

# Start check of variables contained in data sheets

# Create an empty list to store results
results <- list()

# Initialize variables to store totals
total_non_missing <- 0
total_missing <- 0


# Iterate over sheet names
for (i in data_start_position:(length(ls_sheets) - dictionary_length)) {
  sheet_name <- ls_sheets[[i]]
  df_name <- make.names(sheet_name)
  
  # Calculate total number of non-NA values for each column
  non_na_counts <- colSums(!is.na(get(df_name)))
  
  # Calculate total number of missing values for each column
  missing_counts <- colSums(is.na(get(df_name)))
  
  # Calculate total non-missing and missing values for this sheet
  total_non_missing_sheet <- sum(non_na_counts)
  total_missing_sheet <- sum(missing_counts)
  
  # Update totals
  total_non_missing <- total_non_missing + total_non_missing_sheet
  total_missing <- total_missing + total_missing_sheet
  
  # Create a data frame to store the results for this sheet
  sheet_results <- data.frame(
    Sheet_name = sheet_name,
    Variable = names(non_na_counts),
    Non_NA = non_na_counts,
    Missing = missing_counts
  )
  
  # Append the sheet results to the list
  results[[i]] <- sheet_results
}

# Print totals
cat("Total Non-Missing Values across all sheets:", total_non_missing, "\n")
cat("Total Missing Values across all sheets:", total_missing, "\n")

# Combine all the sheet results data frames into a single data frame
tabulated_values <- do.call(rbind, results)

# Print or return the final result
tabulated_values <- data.frame(tabulated_values, row.names = NULL)
# Shorten values of Variable if .GT. 30
tabulated_values$Variable <- substr(tabulated_values$Variable, 1, 30)
tabulated_values$Variable <- format(tabulated_values$Variable, justify = "left")
tabulated_values$Sheet_name <- format(tabulated_values$Sheet_name, justify = "left")
# Set a higher value for max.print
options(width = 90, max.print = 10000)  # Adjust the value as needed

tabulated_values <- left_align_column_names(tabulated_values)
print(tabulated_values, row.names = FALSE)
```

\newpage
# 3.0. Coherent Identifiers?

Index variables ('keys' in database terminology) from pairs of data frames are compared to make sure that the index values are identical across the sheets. This is fundamental to allowing different types of data to be linked across sheets. For example the values of 'Field location' should be the same in the sheets 'E1. Treatments' and 'E2. Fields'.

The basic approach for testing:

1.  Create two temporary data frames.
2.  Merge the data frames based on identifiers given as a list in the argument 'TestVar'.
3.  Reduce the two data frames to just the columns corresponding to 'TestVar'.
4.  Extract the unique combinations of values for each data frame.
5.  Add flag variables, 'from_df1' and 'from_df2', to make it easier to detect problems.
6.  Merge the the two data frames to create 'dfMerged'.
7.  Compare the length of the two data frames. The lengths should be identical.
8.  Print the merged test dataset 'dfMerged' to allow inspection by the users.

If the two frames are of different lengths, then there is a problem. If the two data frames are of the same length, one should still review 'from_df1' and 'from_df2' to see whether there are mismatches, which would be indicated by 'NA' in one of the two columns.

Common sources of mismatches include:

-   Inconsistent use of spaces such as 'Blk 1' vs. 'Blk1'.
-   Simple spelling errors ('Fred' vs. 'Frred')
-   Experiments, treatments or plots that were either never planted or not harvested.
-   Extra rows being read in a given sheet, leading to an empty cell being assigned a value of NA. This may arise if a stray character appears outside of the intended range of data.

In the third case, it is helpful to provide a comment or note in the appropriate sheets.

```{r, create-TestIdsEqual, echo = FALSE, comment=""}
# Function to test whether identifiers match in list 'test_vars'
# First need a function to left adjust the list of test variables, test_vars
left_align_columns <- function(df, columns) {
  df[columns] <- lapply(df[columns], function(col) {
    if (is.character(col)) {
      format(col, justify = "left")
    } else {
      col
    }
  })
  return(df)
}

# Here is the main function
test_ids_equal <- function(df_test1, df_test2, test_vars) {
  df1_name <- deparse(substitute(df_test1))
  df2_name <- deparse(substitute(df_test2))
  
  # Test whether either df is empty with nrow()
  if (nrow(df_test1) == 0 || nrow(df_test2) == 0) {
    cat(paste("Insufficient data to test merge of ", df1_name, " and ", df2_name), "\n")
  } else {
    df1 <- df_test1[, test_vars]
    df2 <- df_test2[, test_vars]
    
    df1 <- unique(df1)
    df2 <- unique(df2)
    
    df1 <- as.data.frame(df1)
    df2 <- as.data.frame(df2)
    
    colnames(df1) <- test_vars
    colnames(df2) <- test_vars
    
    df1$From_df1 <- 1
    df2$From_df2 <- 1
    
    df_merged <- merge(df1, df2, all = TRUE)
    
  # With merged set of identifiers, we need to check if lengths are equal.
  if (nrow(df1) > nrow(df2)) {
      message <- paste(df1_name, " is longer than ", df2_name)
    } else if (nrow(df1) < nrow(df2)) {
      message <- paste(df2_name, " is longer than ", df1_name)
    } else {
      message <- paste("The sheets ", df1_name, " and ", df2_name, " have the same length")
    }
    
    print(message, row.names=FALSE, quote = FALSE)
    df_merged <- left_align_columns(df_merged, test_vars) #Left adjust the variables being tested
    print(df_merged, row.names=FALSE)
  }
}
```

\newpage

## 3.1. Comparing identifiers used in M1. Experiments, E1. Treatments, E2. Fields and E3. Plots

```{r, compare-IDs-M1-vs-E1-E3, echo = FALSE, comment=""}

#' Using TestIdsEqual() to compare identifiers in the sheet E1. Treatments
#' with values used in other sheets such as E2. Fields.
test_ids_equal(M1..Experiments, E1..Treatments, "Experiment ID")
test_ids_equal(E1..Treatments, E2..Fields, "Experiment ID")
test_ids_equal(E1..Treatments, E2..Fields, c("Experiment ID", "Site"))
test_ids_equal(E1..Treatments, E2..Fields, c("Experiment ID", "Site", "Field location"))
test_ids_equal(E1..Treatments, E3..Plots, c("Experiment ID", "Site", "Field location"))
```

---

## 3.2. Comparing identifiers used in E2. Fields vs. E3. Plots

```{r, compare-IDs-E2-vs-E3, echo = FALSE, comment=""}

#' Using TestIdsEqual() to compare identifiers in the sheet E2. Treatments
#' with values used in other sheets such as E3. Plots.
test_ids_equal(E2..Fields, E3..Plots, "Field location")
test_ids_equal(E2..Fields, E3..Plots, c("Experiment ID","Field location"))
```

---

## 3.3. Comparing identifiers used for soil and weather data

Note that the same soil profile or weather data may be used for several experiments or nearby sites.

```{r, compare-IDs-soil-weather, echo = FALSE, comment=""}

# Using test_ids_equal() to compare identifiers in other sheets such as for soils 
# and weather. 
test_ids_equal(E2..Fields, S1..Soil.Metadata, "Soil ID")
test_ids_equal(S1..Soil.Metadata, S2..Soil.Layer.Properties, "Soil ID")
test_ids_equal(E2..Fields, W1..Weather.Station.Metadata, "Weather station ID")
#test_ids_equal(W1..Weather.Station.Metadata, W2_Daily.Weather.Data, "Weather station ID")
```

---

## 3.4. Comparing identifiers in E1..Treatments and the various management sheets

Testing for matches is extended to sheets for irrigations, fertilizers, etc. Because not all sheets will have data, we first create a list of sheets with data (number of rows \> 0).

```{r, compare-IDs-E1-vs-management, echo = FALSE, comment=""}

df_list <- lapply(ls_sheets, make.names)
df_non_zero <- list()
j <- 1

# Filter the dataframes that meet the conditions
for (i in 8:(length(df_list) - 3)) {
  df <- df_list[[i]]
  if (nrow(get(df)) > 0) {
    df_non_zero[[j]] <- df
    j <- j + 1
  }
}
#' We loop through df_non_0 to check for matching of Experiment IDs with the 
#' corresponding levels in the Treatments data frame.
#' The last seven sheets are excluded because they don't use Experiment.ID.
for (i in 2:(length(df_non_zero) - 7)) {
  test_df <- df_non_zero[[i]]
  cat(paste("Comparing E1..Treatments to", test_df, "for Experiment ID", "\n"))
  test_df <- get(test_df, envir = parent.frame())
  test_ids_equal(E1..Treatments, test_df, "Experiment ID")
  cat("\n")
}
```

\newpage

# 4. Compatible?: Checking That Variables Are Properly Described And Linked

We check whether all variables given in the various sheets appear in one of the three dictionary sheets. The dictionaries include variable names and definitions from the ICASA standards, so correct matching is needed to allow a dataset to be read by tools that use the ICASA standards. 

A common source of mismatches is when a variable is added to crop or soil measurements but is not added in the dictionary sheets. When variables are present in both sources, possible causes of mismatches include:

- Differences in capitalization or punctuation
- Names with trailing blank spaces

We also check whether all variables have definitions and are linked to ICASA short names.
The processing works from the list of data frames, ls_sheets, but excludes the first three sheets and the three dictionaries.

```{r check-variables-in-dictionary, echo = FALSE, results='asis', comment=NA}

df_list <- as.list(ls_sheets)
df_variables_used <- data.frame()

#' We iterate through the data frames, skipping first three "readme"-type sheets
#' and last three sheets, which are the dictionaries.
for (i in data_start_position:(length(df_list) - dictionary_length)) {
  # Extract the data frame
  df <- get(make.names(df_list[[i]]))
  
  # Extract the column names
  variable_names <- names(df)
  
  # Check if there are any columns in the dataframe
  if (length(variable_names) > 0) {
    # Create a data frame with the dataframe name and variable names
    temp_result <- data.frame(sheet_name = rep(df_list[[i]], times = 1, each = length(variable_names)),
                              VariableName = rep(variable_names, times = 1, each = 1),
                              stringsAsFactors = FALSE)
    
    # Bind the current result to the overall result data frame
    df_variables_used <- rbind(df_variables_used, temp_result)
  }
}
# Return the final result data frame.
# df_variables_used
# Replace ".." with period-white space (". ") for sheet names
df_variables_used$SheetName <- gsub("  ", ". ", df_variables_used$sheet_name) 
# Replace "." with white space (". ") for variable names
df_variables_used$VariableName <- gsub("\\.", " ", df_variables_used$VariableName) 
df_variables_used$InVUsed <- 1
  
#' We create a single dictionary data frame from the three dictionaries in the 
#' Excel file.
df_dictionaries <- rbind(Z1..Dictionary.Metadata, Z2..Dictionary.Observations)
df_dictionaries <- rbind(df_dictionaries, Z3..Dictionary.Soils.Weather)
df_dictionaries$InDict <- 1
df_dictionaries$var_defined <- ifelse(!is.na(df_dictionaries$Definition)
                                      & !is.na(df_dictionaries$Definition), 1, 0)
df_dictionaries$has_ICASA_short <- ifelse(!is.na(df_dictionaries$'ICASA short name')
                                          & !is.na(df_dictionaries$'ICASA short name'),
                                          1, 0)

# names(df_dictionaries)
```

## 4.1. Comparing the number of variables either used in the sheets or defined in the dictionaries

The initial check is whether the data sheets have roughly the same number of variables as the three dictionary sheets.

```{r, compare-variable-numbers, echo = FALSE, comment=""}

cat(paste("Total variables in the spreadsheet: ", nrow(df_variables_used)))
cat(paste("Total variables in the three dictionaries: ", nrow(df_dictionaries)))
```

---

## 4.2. Compare lists of variables used in data sheets vs. the dictionaries

The second, more extensive check uses variable-by-variable matching. Mismatched variables are listed below. The columns InVUsed ("Included in Variables Used") and InDict ("In the Dictionaries") have a value of 1 if the variable is present in the respective source, the data sheets or the dictionaries. A value of NA means there is a mismatch. 

The script displays only mismatches, 'VariableName' is truncated to 35 characters so that each comparison will appear on a single line.

```{r Check-variable-names, echo = FALSE, warning=FALSE, comment=""}

check_dictionary_main <- merge(df_variables_used, df_dictionaries, 
                          by = c("SheetName", "VariableName"), all = TRUE)
check_dictionary_main$InVUsed <- ifelse(check_dictionary_main$InVUsed ==1
                                        & !is.na(check_dictionary_main$InVUsed), 1, 0)
check_dictionary_main$InDict  <- ifelse(check_dictionary_main$InDict  ==1
                                        & !is.na(check_dictionary_main$InDict), 1, 0)

check_dictionary <- check_dictionary_main[, c(1, 2, 4, 11)]
check_dictionary$VariableName <- substr(check_dictionary$VariableName, 1, 35)

check_dictionary <- data.frame(check_dictionary)
mis_match <- subset(check_dictionary, is.na(check_dictionary$InVUsed == 1 
                                      & check_dictionary$InDict == 1))

if (nrow(mis_match) > 0) 
    {mis_match2 <- left_align_column_names(mis_match)
     print(mis_match2, row.names = FALSE)
} else {
      print("[All variables used are preseent in the Dictionary worksheets.]")
    }

cat("\n")
```

---

## 4.3. Checking whether all variables used in the data sheets are defined.

The list below contains all variables that lack a definition ('var_defined' = 0).

```{r Check-var_defs, echo = FALSE, warning=FALSE, comment=""}

check_dictionary2 <- check_dictionary_main[, c(1, 2, 3, 11)]
check_dictionary2$VariableName <- substr(check_dictionary2$VariableName, 1, 35)

un_defined_vars <- subset(check_dictionary2, check_dictionary2$var_defined == 0 
                          & check_dictionary2$InVUsed == 1)
un_defined_vars <- left_align_column_names(un_defined_vars)

if (nrow(un_defined_vars) > 0) 
    {un_defined_vars <- left_align_column_names(un_defined_vars)
     print(un_defined_vars, row.names = FALSE)
} else {
      print("[All variables used have associated definitions.]")
    }

cat("\n")
```

---

## 4.4. Checking whether all variables are linked to an ICASA short name.

The list below contains all variables that are *not* associated with an ICASA 
variable.

```{r Check-var_ICASA, echo = FALSE, warning=FALSE, comment=""}

check_dictionary3 <- check_dictionary_main[, c(1, 2, 3, 12)]
check_dictionary3$VariableName <- substr(check_dictionary3$VariableName, 1, 35)

no_ICASA_short <- subset(check_dictionary3, check_dictionary3$has_ICASA_short == 0 
                          & check_dictionary3$InVUsed == 1)


no_ICASA_short$sheet_name <- format(no_ICASA_short$sheet_name, justify = "left")
no_ICASA_short$VariableName <- format(no_ICASA_short$VariableName, justify = "left")

if (nrow(no_ICASA_short) > 0) 
    {no_ICASA_short <- left_align_column_names(no_ICASA_short)
     print(no_ICASA_short, row.names = FALSE)
} else {
      print("[All variables used have associated ICASA short name.]")
    }

cat("\n")
```

---

## 4.5. Checking the Workbook for Formulas, Merged Cells or Commented Cells

One concern with use of spreadsheets is that , merged cells, comments attached to specific cells, or other features  might cause problems in subsequent use of the data. We test first for use of formulas and merged cells, then test for comments attached to specific cells.
The checking script only returns the cell address (e.g., 'B17') or range ('B5:C2'). To save space in the report, only first 20 cases are displayed.

### 4.5.1. Checking spreadsheet for formulae or merged cells

Use of formulas is dangerous in datasets that are redistributed because they may results in values being updated incorrectly.

When read by software expecting complete rows and columns, values of merged blocks of cells are typically assigned only to the upper left cell of a merged block, and other cells are assumed to have missing values. To avoid possible misinterpretation of data, all merged cells should be un-merged.

```{r check-formulae-merges, echo = FALSE, comment=""}
#' Checking for formulas and merged cells in spreadsheet

for (k in 4:length(ls_sheets)) {        # Loop from first sheet to end of list
  # Get sheet for checking
  sheet <- ls_sheets[[k]]  
  # Test for formulas in cells
  formulas <- wb$worksheets[[k]]$sheet_data$cc
  # print(formulas)
  formulas <- formulas[formulas$f != "" 
                       | formulas$f_t != "" | formulas$f_ref != "" 
                       | formulas$f_ca != "" | formulas$f_si != "", c("row_r", "c_r")]
  
  if (nrow(formulas) > 0) {
  #  cat("Report for sheet: ", sheet, "\n")
    if (nrow(formulas) > 20) {formulas <- formulas[1:20, ]}
    cat("> For ", sheet, " formulas found at:\n")
    print(formulas, row.names = FALSE)
    cat("(Only first 20 instances of cells with formulas are shown.)\n")
  } #else {
    #cat("> No formulas found.\n")
    #}
  # cat(typeof(formulas))
  
  # Test for merged cells based on xml properties in sheet
  merge_cells <- wb$worksheets[[k]]$mergeCells # Extracts information about merged cells within the "testing" worksheet.
  merge_cells <- gsub("<mergeCell ref=\"", "", merge_cells)
  merge_cells <- gsub("\"/>", ",", merge_cells)
  len_merge_cells <- length(merge_cells)
  if (len_merge_cells > 0 & (merge_cells[1] == "A1:F1," | merge_cells[1] == "A1:G1,")) {
    merge_cells <- merge_cells[-1] # Negative index removes first element
    len_merge_cells <- len_merge_cells - 1
  }
  if (len_merge_cells > 20) {
    merge_cells <- merge_cells[1:20]
  }
  if (len_merge_cells > 0) {
    cat("> For ", sheet, " merged cells found at:\n")
    print(merge_cells, row.names = FALSE)
    cat(paste("\n","(Only the first 20 cell ranges are displayed.)\n\n"))
  } #else {
  #   cat("> No merged cells found.\n\n")
  # }
}

```

---

### 4.5.2. Checking for cells with attached comment

If specific comments are attached to cells, the information may be lost in subsequent processing. The preferred way to record comments is in note or comment variables on the respective sheet.

```{r check-comments, echo = FALSE, comment=""}
#' Test for cells with comments based on xml properties in workbook.
#' This is more complicated than one might expect because comments are
#' stored directly with cell values.
#' cat("Processing comments here\n\n")
comment_index <- data.frame()

#' Loop over sheets to create a dataframe that links sheets to the index 
#' used to link comments to sheets.
for (k in 4:length(ls_sheets)) {        # Loop from 1 to length of list
  # Extract key to relate index in comments to worksheets
  len <- length(comment_index)
  comment_relation <- wb$worksheets[[k]]$relships$comments
  # print(typeof(comment_relation))
  comment_relation <- ifelse(length(comment_relation) == 0, 0, comment_relation) 
  comment_index <- rbind(comment_index, c(k, comment_relation))
}
names(comment_index) <- c("sheet_number", "comment_relation")

#' Loop over list of comments to create a dataframe that links cell addresses
#' to the comment index 

comment_cells <- data.frame()
comments <- wb$comments
if (length(comments) > 0) {
  for (i in 1:length(comments)) {
    for (j in 1:length(comments[[i]])) {
        # print(comments[[i]][[j]]$ref)
        comment_cells <- rbind(comment_cells, c(i, comments[[i]][[j]]$ref))
      }
    }

  names(comment_cells) <- c("comment_relation", "cell")
  comment_cells <- merge(comment_index, comment_cells)
}

#' Report on sheets containing comments.
for (k in 1:length(ls_sheets)) {        # Loop from 1 to length of list
  comments_in_sheet <- comment_cells[comment_cells$sheet_number == k, ]
  ifelse(nrow(comments_in_sheet) > 20, comments_in_sheet[20, ], comments_in_sheet)
  # print(nrow(comments_in_sheet))
  if (nrow(comments_in_sheet) > 0) {
    cat(paste0("'", ls_sheets[k], "' contains cells with comments.\n"))
    cat(paste("The cells with comments are:\n"))
    print(comments_in_sheet[, 3])
    cat("(Only the first 20 cells are displayed)\n\n")
  }
  # else {
  #   cat(paste0("'", ls_sheets[k], "' had no cells with comments.\n\n"))
  # }
}

```

If no sheets are listed above, then no comments attached to cells were found.

---

```{r, echo = FALSE, results = 'asis'}
# Generate header text based on data/variables
header_text <- paste0("# End of analysis for \n\n## ", data_set_name)
cat(header_text, "\n")
```

Please send questions or feedback to Jeffrey W. White.

Users who are familiar with R and Rmarkdown are encouraged to modify the script as needed.

---